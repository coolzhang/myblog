# 如何打造云上数据库运维体系

## 背景与规划
微影作为票务行业的先锋之一，承载着市场三分之一的流量，如何给用户提供最稳定的服务，是我们整个研发中心的使命，作为后端数据掌管者意义更加重大，如何保证公司核心资源的数据能够被各业务部门高效安全的使用，这便是我们DBA的职责所在，下面将逐一介绍微影基于云上资源打造的数据库运维体系。

2015年五一过后不久便加入微影，刚来的时候现有业务数据库都跑在腾讯云CDB服务上，订单与运营系统在自建的MongoDB上，前端缓存有memcached也有redis基本上也都是自建。微影所有线上业务均部署在腾讯云上，后续的运维管理也都是围绕云来开展，在对现有业务熟悉之后，我们便开始着手规划日常运维系统。

首先，我们要建立一套安全可靠的备份与恢复系统，数据重于泰山备份能救命；在完善备份的同时，每天也会面临来着业务方的各种问题，为了便于问题排查以及及时报障，基于zabbix的监控平台也陆续搭建起来；随之而来的就是考虑如何保证数据服务的高可用，充分发挥云上资源丰富简单的特点，对于多元化的数据库产品分别制定简单有效的高可用方案；在逐步保证业务稳定运行之后，便开始了自动化运维实践，先是日常工具脚本化，再实现定时任务自动化，最后逐步向服务自助化靠近。这便是我们数据库运维体系的推进时间线，下面就具体介绍下每个系统的权衡考量与最终实现。

## 备份恢复系统

### MySQL部分
* **设计思路**：可配置，具备有效性检查。
* **实现细节**：
	* ***配置选项***：
        * 工具类型(`tool`)：mysqldump与xtrabackup，例如：根据每天恢复校验的时间作为衡量，10分钟以内的使用mysqldump，大于10分钟调整为xtrabackup
        * 备份周期(`week`)：一周7天，例如：ALL(每天备份)，Mon,Wed,Fri(每周一三五备份)
        * 备份保留(`interval`)：默认7天
   	* ***备份工具***：`mysqldump`（逻辑备份，备份中小型实例，跨版本升级，备份内容比较灵活）与`xtrabackup`（物理备份，备份巨型实例效率高）
	* ***备份策略***：全备+binlog增量（`mysqlbinlog 5.6`）
	* ***备份检查***：实现doublecheck，第一次检查发生在备份完成，通过搜索备份文件或者备份日志结尾的关键字(`mysqldump:{Dump completed}`,`xtrabackup:{completed OK}`)进行备份完整性的初步判断,第二次检查会在专属备份机上做真实的恢复操作，同时还会执行特定的sql对实例中的库表做真实的统计以确保数据可用。
	* ***备份保留***：从机上只保留当天备份，专属备份机上会根据配置保留天数预留备份。
* **注意点**：
    * 备份会跟线上实例争抢I/O以及内存资源，有时为了保证数据一致性还会去申请相应锁资源，某些备份工具还会对上线实例的bufferpool造成"污染"，比如：mysqldump/mydumper，这样不免会对线上业务产生或大或小的影响，所以通常我们会将备份任务安排到业务低峰期，或者选择在从库上进行备份。
    * 随着业务量的不断扩大备份消耗的存储空间也在持续增长，所以为了空间最大化我们会对备份后的文件进行压缩，基于压缩比和速度两方面的综合考虑选取一些高效的工具，比如：pigz/unpigz。
    * 当从库通过rsync将备份同步到备份机时，备份机的网卡带宽也是我们需要关注的，随着备份数据量的增加如果所有同步操作恰好都在相邻的时间发生，很容易就会将远端网卡跑满而触发报警，其实可以换个策略，将之前多台从库推送的方式，改为备份机主动拉取的方式，这样就由并发同步转换串行同步，从而减少对备份机的压力。

### Redis部分
几乎所有的业务前端都会设计一个cache层，以提高访问效率。对于redis的使用既有作纯缓存的也有当作存储的，作为缓存那么业务设计上是允许丢失的，因为后端MySQL可以提供所有数据，作为存储就以为这这些数据不会另外存储到其他地方，那么也就是说这些数据是不可失的，我们既没有采用`RDB`也没有使用`AOF`，而是根据实际业务量采用主从的方式来保证数据的可靠性，进而避免持久化带来的相关问题，保证服务始终高效稳定对外服务。

### MongoDB部分
线上采用的是副本集架构给业务提供读写服务，虽然有多副本冗余，但对于防范误操作备份依然是必不可少的一个环节，日常工具我们使用的是360开源的`mongosync`。之前我们曾它来做版本升级，简单易用而且数据复制的性能相当出色，故有了之后尝试通过mongosync来作为备份工具的想法，每天定时通过数据复制将线上实例同步到备份机上的实例中，与之前迁移数据不同的是不会开启同步oplog的选项。另外，需要注意的是，由于mongosync支持并发复制，可以最大化使用系统资源，会充分消耗网卡带宽，为了减少对线上节点造成影响，可以适当调整复制线程并发数，并选择业务低峰期进行，数据源也可以选择从非主节点进行复制。


## 监控报警系统

监控软件选择企业级监控产品`Zabbix`(它同时支持趋势图与报警功能，在当前机器数量下，数据收集性能能很好的满足我们的需求)，数据库模板采用Fromdual开源的`MPM`模板(Perl版本)，Redis模板自建，MongoDB模板使用的第三方开源的`Mikoomi`模板。

#### MySQL部分
数据采集zabbix agent端采用主动模式，推送数据给zabbix server端，MPM agent触发MySQL.check默认是90s一次，根据业务实际需求以及启动监控项的数量综合考虑调整数据采集的频率。另外需要注意的是，mpm.conf文件支持配置多实例，随着监控实例的增多，如果采集频率又配置太过频繁的话，日志中很容易看到跟`*AgentLock*`相关的信息，导致其他实例数据采集不能正常完成，趋势图中出现断点，此时如果有故障发生也不能及时发出报警。

用到的监控模板分为5种，监控项200+，报警项30+，趋势图20+：

    * Fromdual.MySQL.mpm - mpm agent服务自身监控，同时根据采集频率的配置定期触发数据收集；
    * Fromdual.MySQL.mysql - server层各项监控信息；
    * Fromdual.MySQL.innodb - innodb存储引擎特有的监控信息；
    * Fromdual.MySQL.master - 复制监控中关于主库binlog信息；
    * Fromdual.MySQL.slave - 复制监控中关于从库同步状态信息。

#### Redis部分
监控脚本与模板均根据实际需求由运维同学(cailu)自己定义创建，主要根据info命令输出信息进行统计，使用zabbix的`LLD`(low level discovery)特性自动发现agent上的redis服务实施监控，通常一台CVM上会启动多个Redis实例。另外，见于监控项比较少，而redis信息收集又非高效，虽然实例个数已过百，监控模式选择被动，，由server端根据模板配置定期向agent要数据，实际中server端没有任何压力；采集频率根据不同的监控项差异化配置，参数选项选择小时级别，状态项选择妙级别。

目前监控项13个，报警项3个，趋势图3张，分为以下3分类：

    * Clients and Stats - 连接数统计、QPS、慢查询、以及输入/输出缓冲；
    * Keyspace - 实例总key数统计；
    * Memory - 分配最大内存数、实际使用量、以及碎片率。

#### MongoDB部分
采用开源的PHP项目Mikoomi，server端通过`External check`的方式，根据配置的更新频率调用外面脚本触发收集动作，agent端通过`Trapper`模式主动将数据发送给server端完成数据采集。需要注意的是，由于模板比较老之后没有持续更新，脚本对于3.0以后的版本已经不能兼容，特别是对于新引擎`WiredTigger`也没有对应监控项与趋势图，需要我们自己通过修改PHP脚本来补充。

模板自带监控项71个，报警项17个，趋势图7张，可以将其选项分为7类：

    * BackgroudFlushing - 针对mmapv1引擎统计1分钟内的刷新磁盘的次数，以及平均刷新消耗的时长
    * Connections - 当前连接数
    * GlobalLock Queue - 等待读锁、写锁的操作个数据(该指标如果持续升高说明当前实例异常)
    * Index - 反映索引命中率的高低
    * Memory - 内存使用情况，以及碎片率
    * Opcounter - 每秒查询更新情况(默认是分钟，我们修改了模板)
    * Total of sizes of DBs - 实例总容量

## 高可用系统

每个数据库产品根据其自身特点都有各自的高可用方案，由于使用环境与场景的不同，最终落地方案的优雅程度也各有差别，前面介绍过我们所有服务均部署在云上，可以充分发挥云上资源多样化、简单易用以及灵活的特点，再结合业务对于稳定的具体要求，从而设计出一系列应对不同数据库产品的高可用方案，下面将逐一介绍。当然，云上也也提供了现成的服务化的产品可以直接使用，自然上面说的所有工作都不用费心了，高可用也在其中。

### MySQL部分
MySQL自带原生的复制机制，经过互联网大潮的磨炼之后，现在已经相当的稳定可靠，但由于原始设计，在某些场景下会导致各节点副本不一致，也就是通常我们说的丢失数据问题，主从复制不能够完全保证复制节点数据的可靠，于是便有了很多基于主从复制的高可用方案，我们选择了其中一个方案：**`MHA`**。

* **理由**：MHA是一个脚本解决方案，简单高效，不需要额外机器资源，也不需要修改现有架构体系；由两个角色构成，master manager负责监控已经后续触发自动化切换，node也就是所有复制节点，在主库服务器可以访问的前提下是可以实现提升后的从库完全跟主库数据保持一致。MHA帮我们解决了，在`GTID`出现前一系列切换前需要的准备工作，比如：哪个从库数据是最新的，从库之间的差异如何补全，主库与从库之间还差哪些数据故障前没有同步过来，特别是当复制架构中有很多从库的时候，MHA的魅力显得格外耀眼，简约而不简单，30秒内解决你的一切烦恼。另外一个值得称道的地方就是它的文档，相当的完整细致，简单易懂，Yoshi还分享了一个几十页的PPT对于MHA原理进行了详细的说明。
* **不足**：由于该方案是基于原生复制而设计，无论配置的是`semi-sync`的after\_commit还是after\_sync，都会因为网络异常发生复制模式退化，异步复制就会存在主从数据延时问题，所以终究还是绕不过不丢数据的考验；其次，在判断服务是否可用的方式上也不够严谨，尽管除了可以进行简单的ping探测心跳外，还支持select/insert模拟真实语句探测，但是网络抖动很容发生误判导致切换，语句探测有时会因为实例繁忙不能正常响应也同样会做出误判；还有manager自身也存在单点问题，这种常见的由一个服务监控另一个服务的方式，始终会面临谁来监控自己的问题。但不可否认MHA在一个时期某些场景下依然很有效的解决了业务方对于数据库的可靠性需求。

那有没有真正解决数据不丢失的方案呢，答案是肯定的，而且还不止一种，下面就简单介绍下：

* **共享存储** - 我们都是知道MySQL的架构特点是`share-nothing`，就是说每个实例有独立的物理存储空间，各实例间是不共享的，所有你看到的方案里面无论是主库还是从库数据都是由本实例所有，各节点的数据都是一样的。与其相对的就是`share-everything`，最有名的当属Oracle RAC，无论前面多少个SQL节点，后面的数据只会写入到一个地方，也就是所有实例共享一个存储空间。MySQL虽然不能像Oracle一样多个实例访问同一个存储，但是我们可以借鉴共享的思路，在同一时间只启动一个实例，备实例处于静止状态，当故障发生时立即启动即可，由于数据保存在安全可靠的独立存储上故不存在数据丢失的问题。
* **Galera插件** - `Galera`是一个通用的同步复制插件，支持多主复制，并能对同步数据进行校验保证各节点数据完全一致。目前流行的相关实现有：`Percona XtraDB Cluster`(PXC)和`MariaDB Galera Cluster`。
* **组复制** - `MGR`(MySQL Group Replication)是MySQL官方从5.7开始支持的*全新*复制方案，基于分布式一致性算法Paxos和自研组复制协议，通过新增的XCom组件实现多节点数据同步，并通过Certify模块进行事务冲突检测来保证各节点事务一致性，支持单节点更新和多节更新，允许少数节点故障并自动完成可用节点的选举操作，目前还不太稳定仍在不断优化中。另外，配合官方中间件产品MySQL Router可以实现一套完整的高可用方案，即InnoDB Cluster。

### Redis部分
Redis作为我们的第一大资源，业务对于它的依赖可见一斑。Redis具有丰富的数据类型，高效无比的存取性能，同时还支持持久化与数据复制功能，既可以当缓存使，也可以作存储用。我们的策略是，对于Redis中不可丢失的数据一定会配置从库，我们没有选择持久化，选择用钱解决问题，对于纯缓存的数据，如果该业务流量很大，也会适当配置从库，避免意外宕机对于后端数据库造成雪崩。高可用我们采用的是LBIP+Sentinel+主从复制的方案，腾讯云现成的VIP服务，业务方通过VIP访问，后端Redis实例的调整对其实透明的，`Sentinel`本身是一个分布式服务，可以用来监控主从实例的状态并触发切换，同时通过配置相应参数让Sentinel调用我们定制化的脚本完成最终切换。脚本主要实现了两个功能一是完成腾讯云LBIP的配置变更，二是触发报警短信。

### MongoDB部分
MongoDB副本集本身就自带故障切换功能，无需借助外界任何辅助手段，运维上非常友好。另外，还自带读写分离选项，通过客户端参数配置即可轻松实现。

## 自动化运维系统

* **初始化服务** - 采用开源的配置管理系统`Saltstack`，首先需要定义minion-id，经过不断实践最后确定了ID构成，包括：业务名称-产品名及角色-IP-端口，然后定义对应功能的SLS文件，分为：install.sls、monitor.sls、backup.sls、repl.sls、mha.sls，实现了从格式分区、初始化系统内核参数、到安装配置数据库、主从搭建、再到下发备份以及日常维护脚本、添加监控、最后部署高可用，完成了数据库服务器一键式初始化。在不断完善SLS的过程中，我们也总结了一些编写经验，比如sls脚本应该是幂等(即可以反复多次执行)，sls中可以适当定义变量但尽量减少手工改动，sls中的id声明可以定义为对应linux命令或者功能解释，sls内states的执行顺序可以巧妙的通过加字母前缀来保证有序。

* **慢语句优化** - 为了方便排查统计各个系统SQL语句的执行情况，我们通过第三方开源软件`Box Anemometer`搭建了慢查询系统。

* **表结构变更** - 使用Python的web框架`Flask`简单实现了一套数据库上线自助系统，SQL审核功能使用的去哪儿网开源的数据库中间件产品`Inception`。该系统与内部工单系统绑定，开发提交工单后，通过工单号即可获得登陆系统的权限，填入必要信息校验核实后，方可执行上线SQL，由设置好规则的Inception完成最后的审核和执行操作。系统上线后，减少了开发等待DBA审核的时间，DBA节省出的时间可以用于新技术学习和实践，开发在使用过程中也会主动了解数据库开发规范，后期通过统计审核过程中出现的问题，可以有针对性地为开发提供数据库相关培训。









